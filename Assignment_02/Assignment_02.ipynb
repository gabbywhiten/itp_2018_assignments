{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas and Matplotlib Homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the libraries using the normal convention\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "##prevent plotting errors\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load our excel files of interest into pandas\n",
    "NHL_Goalies = pd.read_excel('NHLGoalies2016_2017.xls',na_values='',sheet_name=0) \n",
    "GAA_ = pd.read_excel('NHLGoalies2016_2017.xls',na_values='',sheet_name='5vs5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Appendix:\n",
    " 1. DF = Pandas DataFrame\n",
    " 2. NHL_Goalies DF = NHL_Goalies \n",
    " 3. GAA_ DF = GAA_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1A) Create a new DF (*called NHL_Ones*) by:\n",
    "#### Filtering the correct DF for Goalies that played 1 game <font color='red'> (GP = Games played)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: How would you find the 'GP' column in these files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Last Name</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>DOB</th>\n",
       "      <th>Birth City</th>\n",
       "      <th>S/P</th>\n",
       "      <th>Cntry</th>\n",
       "      <th>Nat</th>\n",
       "      <th>Ht</th>\n",
       "      <th>Wt</th>\n",
       "      <th>...</th>\n",
       "      <th>Cap Hit</th>\n",
       "      <th>Pace</th>\n",
       "      <th>1st</th>\n",
       "      <th>2nd</th>\n",
       "      <th>3rd</th>\n",
       "      <th>Star</th>\n",
       "      <th>GPS</th>\n",
       "      <th>Ginj</th>\n",
       "      <th>Injuries</th>\n",
       "      <th>CHIP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alves</td>\n",
       "      <td>Jorge</td>\n",
       "      <td>CAR</td>\n",
       "      <td>1979-01-30</td>\n",
       "      <td>Boston</td>\n",
       "      <td>MA</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>69</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Campbell</td>\n",
       "      <td>Jack</td>\n",
       "      <td>LAK</td>\n",
       "      <td>1992-01-09</td>\n",
       "      <td>Port Huron</td>\n",
       "      <td>MI</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>74</td>\n",
       "      <td>197</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Comrie</td>\n",
       "      <td>Eric</td>\n",
       "      <td>WPG</td>\n",
       "      <td>1995-07-06</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>AB</td>\n",
       "      <td>CAN</td>\n",
       "      <td>CAN</td>\n",
       "      <td>73</td>\n",
       "      <td>175</td>\n",
       "      <td>...</td>\n",
       "      <td>645000.0</td>\n",
       "      <td>124.451939</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Copley</td>\n",
       "      <td>Pheonix</td>\n",
       "      <td>STL</td>\n",
       "      <td>1992-01-18</td>\n",
       "      <td>North Pole</td>\n",
       "      <td>AK</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>76</td>\n",
       "      <td>196</td>\n",
       "      <td>...</td>\n",
       "      <td>708750.0</td>\n",
       "      <td>104.864253</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Driedger</td>\n",
       "      <td>Chris</td>\n",
       "      <td>OTT</td>\n",
       "      <td>1994-05-18</td>\n",
       "      <td>Winnipeg</td>\n",
       "      <td>MB</td>\n",
       "      <td>CAN</td>\n",
       "      <td>CAN</td>\n",
       "      <td>76</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>755000.0</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Forsberg</td>\n",
       "      <td>Anton</td>\n",
       "      <td>CBJ</td>\n",
       "      <td>1992-11-27</td>\n",
       "      <td>Härnösand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SWE</td>\n",
       "      <td>SWE</td>\n",
       "      <td>75</td>\n",
       "      <td>192</td>\n",
       "      <td>...</td>\n",
       "      <td>650000.0</td>\n",
       "      <td>110.611664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Gillies</td>\n",
       "      <td>Jon</td>\n",
       "      <td>CGY</td>\n",
       "      <td>1994-01-22</td>\n",
       "      <td>Concord</td>\n",
       "      <td>NH</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>78</td>\n",
       "      <td>223</td>\n",
       "      <td>...</td>\n",
       "      <td>925000.0</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Gudlevskis</td>\n",
       "      <td>Kristers</td>\n",
       "      <td>TBL</td>\n",
       "      <td>1992-07-31</td>\n",
       "      <td>Aizkraukle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LVA</td>\n",
       "      <td>LVA</td>\n",
       "      <td>75</td>\n",
       "      <td>223</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>125.764192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Jarry</td>\n",
       "      <td>Tristan</td>\n",
       "      <td>PIT</td>\n",
       "      <td>1995-04-29</td>\n",
       "      <td>Surrey</td>\n",
       "      <td>BC</td>\n",
       "      <td>CAN</td>\n",
       "      <td>CAN</td>\n",
       "      <td>74</td>\n",
       "      <td>194</td>\n",
       "      <td>...</td>\n",
       "      <td>630833.0</td>\n",
       "      <td>107.234043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Langhamer</td>\n",
       "      <td>Marek</td>\n",
       "      <td>ARI</td>\n",
       "      <td>1994-07-22</td>\n",
       "      <td>Moravska Trebova</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CZE</td>\n",
       "      <td>CZE</td>\n",
       "      <td>74</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>648333.0</td>\n",
       "      <td>88.936627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Nedeljkovic</td>\n",
       "      <td>Alex</td>\n",
       "      <td>CAR</td>\n",
       "      <td>1996-01-07</td>\n",
       "      <td>Parma</td>\n",
       "      <td>OH</td>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "      <td>72</td>\n",
       "      <td>198</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102.170284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Rittich</td>\n",
       "      <td>David</td>\n",
       "      <td>CGY</td>\n",
       "      <td>1992-08-19</td>\n",
       "      <td>Jihlava</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CZE</td>\n",
       "      <td>CZE</td>\n",
       "      <td>75</td>\n",
       "      <td>202</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Subban</td>\n",
       "      <td>Malcolm</td>\n",
       "      <td>BOS</td>\n",
       "      <td>1993-12-21</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>ON</td>\n",
       "      <td>CAN</td>\n",
       "      <td>CAN</td>\n",
       "      <td>74</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>863333.0</td>\n",
       "      <td>107.843137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Tokarski</td>\n",
       "      <td>Dustin</td>\n",
       "      <td>ANA</td>\n",
       "      <td>1989-09-16</td>\n",
       "      <td>Watson</td>\n",
       "      <td>SK</td>\n",
       "      <td>CAN</td>\n",
       "      <td>CAN</td>\n",
       "      <td>72</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.993186</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Ullmark</td>\n",
       "      <td>Linus</td>\n",
       "      <td>BUF</td>\n",
       "      <td>1993-07-31</td>\n",
       "      <td>Lugnvik</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SWE</td>\n",
       "      <td>SWE</td>\n",
       "      <td>76</td>\n",
       "      <td>221</td>\n",
       "      <td>...</td>\n",
       "      <td>775833.0</td>\n",
       "      <td>100.113507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Last Name First Name Team         DOB        Birth City  S/P Cntry  Nat  \\\n",
       "1         Alves      Jorge  CAR  1979-01-30            Boston   MA   USA  USA   \n",
       "13     Campbell       Jack  LAK  1992-01-09        Port Huron   MI   USA  USA   \n",
       "14       Comrie       Eric  WPG  1995-07-06          Edmonton   AB   CAN  CAN   \n",
       "16       Copley    Pheonix  STL  1992-01-18        North Pole   AK   USA  USA   \n",
       "22     Driedger      Chris  OTT  1994-05-18          Winnipeg   MB   CAN  CAN   \n",
       "27     Forsberg      Anton  CBJ  1992-11-27         Härnösand  NaN   SWE  SWE   \n",
       "29      Gillies        Jon  CGY  1994-01-22           Concord   NH   USA  USA   \n",
       "32   Gudlevskis   Kristers  TBL  1992-07-31        Aizkraukle  NaN   LVA  LVA   \n",
       "42        Jarry    Tristan  PIT  1995-04-29            Surrey   BC   CAN  CAN   \n",
       "50    Langhamer      Marek  ARI  1994-07-22  Moravska Trebova  NaN   CZE  CZE   \n",
       "67  Nedeljkovic       Alex  CAR  1996-01-07             Parma   OH   USA  USA   \n",
       "80      Rittich      David  CGY  1992-08-19           Jihlava  NaN   CZE  CZE   \n",
       "87       Subban    Malcolm  BOS  1993-12-21           Toronto   ON   CAN  CAN   \n",
       "89     Tokarski     Dustin  ANA  1989-09-16            Watson   SK   CAN  CAN   \n",
       "90      Ullmark      Linus  BUF  1993-07-31           Lugnvik  NaN   SWE  SWE   \n",
       "\n",
       "    Ht   Wt  ...    Cap Hit        Pace  1st  2nd  3rd  Star  GPS  Ginj  \\\n",
       "1   69  185  ...        NaN    0.000000  NaN  NaN  NaN   NaN  0.0   NaN   \n",
       "13  74  197  ...        NaN   96.000000  NaN  NaN  NaN   NaN  0.1   NaN   \n",
       "14  73  175  ...   645000.0  124.451939  NaN  NaN  NaN   NaN  0.2   NaN   \n",
       "16  76  196  ...   708750.0  104.864253  NaN  NaN  NaN   NaN -0.1   NaN   \n",
       "22  76  205  ...   755000.0  123.000000  NaN  NaN  NaN   NaN -0.2   NaN   \n",
       "27  75  192  ...   650000.0  110.611664  NaN  NaN  NaN   NaN  0.0   NaN   \n",
       "29  78  223  ...   925000.0  109.000000  1.0  0.0  0.0   1.0  0.3   NaN   \n",
       "32  75  223  ...        NaN  125.764192  NaN  NaN  NaN   NaN  0.0   NaN   \n",
       "42  74  194  ...   630833.0  107.234043  NaN  NaN  NaN   NaN  0.0   NaN   \n",
       "50  74  193  ...   648333.0   88.936627  NaN  NaN  NaN   NaN  0.0   NaN   \n",
       "67  72  198  ...        NaN  102.170284  NaN  NaN  NaN   NaN  0.3   NaN   \n",
       "80  75  202  ...        NaN  108.000000  NaN  NaN  NaN   NaN  0.0   NaN   \n",
       "87  74  200  ...   863333.0  107.843137  NaN  NaN  NaN   NaN -0.1   NaN   \n",
       "89  72  205  ...        NaN   91.993186  NaN  NaN  NaN   NaN  0.1   NaN   \n",
       "90  76  221  ...   775833.0  100.113507  NaN  NaN  NaN   NaN  0.2   NaN   \n",
       "\n",
       "    Injuries  CHIP  \n",
       "1        NaN        \n",
       "13       NaN        \n",
       "14       NaN        \n",
       "16       NaN        \n",
       "22       NaN        \n",
       "27       NaN        \n",
       "29       NaN        \n",
       "32       NaN        \n",
       "42       NaN        \n",
       "50       NaN        \n",
       "67       NaN        \n",
       "80       NaN        \n",
       "87       NaN        \n",
       "89       NaN        \n",
       "90       NaN        \n",
       "\n",
       "[15 rows x 111 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Answer 1A:\n",
    "\n",
    "#Create a Data Frame out of the NHL Goalies spreadsheet and simplify to First and Last Name and Games Played.\n",
    "NHL_Ones = pd.DataFrame(NHL_Goalies)\n",
    "\n",
    "#Locate values where GP column is equal to 1.\n",
    "NHL_Ones.loc[NHL_Ones['GP'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " ## Q1B) \n",
    " #### A. Find the value of the minimum Salary for the entire dataset \n",
    " #### B. Replace the missing values from the NHL_Ones DF with this\n",
    " #### C. Create a new DF after replacement by **adding** a column called  \"Adjusted_Salary\"\n",
    " #### D. I would like to only see the old \"Salary\" column and the \"Adjusted Salary\" column from the new Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "1. Note where the minimum Salary value is coming & where you are going to assign it to\n",
    "2. Read up on **replacement** of missing values\n",
    "3. Look up Numpy definition for null\n",
    "4. Look up Pandas **Series** Naming \n",
    "5. Review concat function in Pandas\n",
    "6. Review how to slice columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mimimum Salary is:\n",
      "575000.0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Adjusted_Salary'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-135ef8cb7076>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m#C Make new data frame with Adjusted_Salary column. You can simply append old DF with new column.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mNHL_Ones\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m111\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Adjusted Salary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_salary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mNHL_Ones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Salary'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Adjusted_Salary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/itpf2018/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2681\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2682\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2683\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/itpf2018/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2724\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2725\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2726\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2727\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/itpf2018/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m                     raise KeyError('{mask} not in index'\n\u001b[0;32m-> 1327\u001b[0;31m                                    .format(mask=objarr[mask]))\n\u001b[0m\u001b[1;32m   1328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Adjusted_Salary'] not in index\""
     ]
    }
   ],
   "source": [
    "#Answer 1B:\n",
    "\n",
    "\n",
    "#A: The minimum value can be found using the DataFrame.min() function\n",
    "Min_Salary = pd.DataFrame(NHL_Goalies)\n",
    "print('Mimimum Salary is:')\n",
    "print(Min_Salary['Salary'].min())\n",
    "\n",
    "#B: Need to set all NaN values to 575000 in NHL_Ones\n",
    "\n",
    "#Can replace values with DataFrame.fillna() function\n",
    "Replace_Salary = pd.DataFrame(NHL_Ones)\n",
    "\n",
    "#Replace NaN values with 575000.\n",
    "Replace_Salary['Salary'].fillna(575000, inplace = True)\n",
    "new_salary = Replace_Salary['Salary']\n",
    "\n",
    "\n",
    "#C Make new data frame with Adjusted_Salary column. You can simply append old DF with new column.\n",
    "NHL_Ones.insert(111,'Adjusted Salary', new_salary)\n",
    "NHL_Ones[['Salary', 'Adjusted_Salary']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Q2) A. Subset the NHL goalies data to include Goalies that played in more than 25 games AND have a GAA lower than 3.00 and store the New DF as 'workhorse'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "1. Review notes creating \"boolean\" masks\n",
    "2. Internet search for Multiple Boolean indexing on multiple columns in a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 2:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. Create 2 python functions that: \n",
    "<br> </br>\n",
    "#### A. Creates/*Returns* a new DataFrame that displays the number of missing values in every column. \n",
    "#### This new DataFrame has one new column named \"Missing\" with the sum of the missing values from the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes \n",
    "***Function takes one argument: An input DataFrame***\n",
    "<br> </br>\n",
    "<br> </br>\n",
    "** One Proposed method:**\n",
    "1. Create a pandas series object from the sum of the nulls in every column\n",
    "2. Convert the series object to a DataFrame and pass the list of column names from the input DataFrame as the index. (read Pandas Help online)\n",
    "3. During the conversion of the series object to a DataFrame pass a columns argument to create a name for the new Output DataFrame's Column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output:\n",
    "<img src='Missing_cols_expectedoutput.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer 3A: CODE HERE; Please comment each part\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Creates a new *column* called 'missing_values' in the input DF that sums the missing values in each row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Notes: \n",
    "***Function takes one argument: An input DataFrame***\n",
    "<br> </br>\n",
    "<br> </br>\n",
    "Check out how to use axis argument and how to create new columns in an existing dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output:\n",
    "<img src= 'missingrows_expectedoutput.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 3B here; Please comment each part\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Q4) Matplotlib Question Plot in one figure and 2 side by side plots:\n",
    "<br> </br>\n",
    "#### A. Plot the histogram of the all the GAA of the NHL_Goalies DF  AND the goalies that played in more than 25 games with a GAA < 3.00, \n",
    "#### B. Label the Titles of the plots differently (*ie EntireSet + Subset*)\n",
    "#### C. Change the color of one of the plots from the default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "1. convert your column of interest into a NumPY array (look up online for usage)\n",
    "2. Review: https://matplotlib.org/devdocs/api/_as_gen/matplotlib.pyplot.hist.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 4 here: pleae comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Q5) GroupBy Question\n",
    "##### 1. Subset the NHL_Goalies DataFrame where Injuries is not known <font color='red'>(Injuries=NaN)</font>; \n",
    "##### 2. Use a Merge with the GAA_  DF to produce a NEW DF (*called mergedDF*) \n",
    "###### *** USE A JOIN THAT PRESERVES ORDER AND USES THE INTERSECTION OF KEYS***\n",
    "###### *** USE BOTH THE LEFT AND RIGHT INDEXES AS JOIN KEYS***\n",
    "##### 3. From the mergedDF keep FirstName/LastName/Team/Cntry/ SV% /GA/GAA/ TOI (note one copy for any duplicate column)\n",
    "##### 4. GroupBy country on mergedDF and aggregate The Means, Mins, and Maximum of the kept columns\n",
    "#### 5. Create a dataframe of the <font color='red'>TOI </font>groupby object and write it to a comma seperated value file called ('TOI_2017.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "\n",
    "1. Review or read up pandas documentation on:\n",
    "    - how to create selection criteria\n",
    "    - how aggs/joins work: https://pandas.pydata.org/pandas-docs/stable/merging.html\n",
    "2. https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html\n",
    "3. https://stackoverflow.com/questions/14734533/how-to-access-pandas-groupby-dataframe-by-key\n",
    "4. https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.get.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer 5 here: please comments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q6) Write a function(s)  \n",
    "## that subsets a dataframe by removing rows that are WITHIN the InterQuartile Region of a specified column\n",
    "<br> </br>\n",
    "### The function takes as input \n",
    "##### A: Pandas_Dataframe (For example use NHL_GoaliesDF)\n",
    "##### B. Column name\n",
    "### Add a condition that returns an error if the Column Name chosen is not:\n",
    "##### A. Numeric Dtype\n",
    "##### B. Does not exist in the Numeric Columns\n",
    "### The output is a DataFrame that removes rows outside of the specified columns IQR\n",
    "<br> </br>\n",
    "<font color='red'>**You can use smaller helper functions **<font>\n",
    "<br> </br>\n",
    "See --> <href>=https://en.wikipedia.org/wiki/Interquartile_range</href>\n",
    "#hint: There are several pandas subfunctions that can be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Answer Question 6 here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
